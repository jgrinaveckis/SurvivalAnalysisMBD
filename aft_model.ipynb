{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from lifelines import *\n",
    "from lifelines.plotting import qq_plot\n",
    "from lifelines.utils import find_best_parametric_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data():\n",
    "    train_df = pd.read_csv(r'C:\\Users\\grina\\Desktop\\VGTU\\final_data.csv', index_col=0)\n",
    "    train_df.reset_index(inplace=True)\n",
    "    #replace empty values with 0\n",
    "    train_df.fillna(value=0, inplace=True)\n",
    "    train_df.drop(columns=['name', 'Parachute'], inplace=True)\n",
    "    #change T, F with 1,0\n",
    "    train_df['is_in_blue_zone'] = train_df['is_in_blue_zone'].replace({True:1, False:0})\n",
    "    train_df['is_in_red_zone'] = train_df['is_in_red_zone'].replace({True:1, False:0})\n",
    "    train_df['event'] = 1\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select parametric model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_data()\n",
    "#Q-Q plot for different distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20,20))\n",
    "axes = axes.reshape(4,)\n",
    "for i, model in enumerate([WeibullFitter(), LogNormalFitter(), LogLogisticFitter(), ExponentialFitter()]):\n",
    "    model.fit(df['death_time'].div(60).round(2), df['event'])\n",
    "    qq_plot(model, ax=axes[i])\n",
    "\n",
    "#noone is clearly best choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling LogLogisticAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mms = MinMaxScaler(feature_range=(0, 10), copy=False)\n",
    "df_aft = model_data()\n",
    "df_aft = pd.concat([df_aft, pd.get_dummies(df_aft['playing_type'], prefix='playing_type')], axis=1)\n",
    "df_aft.rename(columns={\"playing_type_1\":\"solo\", \"playing_type_2\":\"duo\", \"playing_type_3\":\"squad\"}, inplace=True)\n",
    "#del multikolinearumo pasalinam duo playing_type_2 atributa\n",
    "df_aft.drop(columns=['duo'], inplace=True)\n",
    "#df_aft.loc[(df_aft['solo'] == 0) & (df_aft['squad'] == 0), 'squad'] = 1\n",
    "df_aft.drop(columns=['distance_sum', 'index', 'playing_type', 'assist', 'item_stack_count', 'damage', 'dist_on_freefall','rank'], inplace=True)\n",
    "not_scaled = ['event', 'solo', 'squad', 'groggy', 'is_in_blue_zone', 'is_in_red_zone', 'death_time']\n",
    "df_scaled = df_aft.drop(columns=not_scaled)\n",
    "\n",
    "#scaling features\n",
    "scaled_features = mms.fit_transform(df_scaled.values)\n",
    "df_scaled = pd.DataFrame(scaled_features, index=df_scaled.index, columns=df_scaled.columns)\n",
    "df_scaled[not_scaled] = df_aft[not_scaled]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_scaled, df_scaled['death_time'], test_size=0.2, random_state=20)\n",
    "\n",
    "aft = LogLogisticAFTFitter(penalizer=5e-2, l1_ratio=0.5)\n",
    "aft.fit(X_train, duration_col='death_time', event_col='event')\n",
    "aft.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax = aft.plot(['dist_on_foot', 'dist_on_vehicle', 'is_in_blue_zone', 'dist_on_swim', 'dist_on_parachute'])\n",
    "plt.title('5 didžiausią įtaką pagreitintam įvykio laikui turintys atributai')\n",
    "plt.xlabel('log(Pagreitintas įvykio laikas), (CI 95%)', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 15))\n",
    "ax = aft.plot(df_aft.columns.tolist())\n",
    "plt.title('Pagreitinto įvykio laiko modelio atributų koeficientai')\n",
    "plt.xlabel('log(Pagreitintas įvykio laikas), (CI 95%)', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ll = model_data()\n",
    "df_ll = pd.concat([df_ll, pd.get_dummies(df_ll['playing_type'], prefix='playing_type')], axis=1)\n",
    "#del multikolinearumo pasalinam duo playing_type_2 atributa\n",
    "df_ll.drop(columns=['playing_type_2'], inplace=True)\n",
    "df_ll.drop(columns=['distance_sum', 'index', 'playing_type', 'assist', 'item_stack_count', 'damage', 'dist_on_freefall', 'is_in_red_zone', 'playing_type_3', 'rank'], inplace=True)\n",
    "\n",
    "llf = LogLogisticAFTFitter(penalizer=0.05).fit(df_ll, 'death_time', 'event')\n",
    "lnf = LogNormalAFTFitter(penalizer=0.05).fit(df_ll, 'death_time', 'event')\n",
    "wf = WeibullAFTFitter(penalizer=0.05).fit(df_ll, 'death_time', 'event')\n",
    "print(llf.log_likelihood_) #best choice, biggest log-likelihood\n",
    "print(lnf.log_likelihood_) \n",
    "print(wf.log_likelihood_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySurvival LogLogisticAFT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysurvival.models.parametric import ExponentialModel\n",
    "from pysurvival.models.parametric import LogNormalModel\n",
    "from pysurvival.models.parametric import WeibullModel\n",
    "from pysurvival.models.parametric import LogLogisticModel\n",
    "from pysurvival.models.parametric import GompertzModel\n",
    "from pysurvival.utils.metrics import concordance_index\n",
    "from pysurvival.utils.display import integrated_brier_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pysurvival.utils.display import display_loss_values\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pysurvival_aft = model_data()\n",
    "df_pysurvival_aft = pd.concat([df_pysurvival_aft, pd.get_dummies(df_pysurvival_aft['playing_type'], prefix='playing_type')], axis=1)\n",
    "#del multikolinearumo pasalinam duo playing_type_2 atributa\n",
    "df_pysurvival_aft.drop(columns=['playing_type_2'], inplace=True)\n",
    "df_pysurvival_aft.loc[(df_pysurvival_aft['playing_type_1'] == 0) & (df_pysurvival_aft['playing_type_3'] == 0), 'playing_type_3'] = 1\n",
    "df_pysurvival_aft['death_time'] = df_pysurvival_aft['death_time'].div(60).round(0)\n",
    "df_pysurvival_aft.drop(columns=['distance_sum', 'index', 'playing_type', 'assist', 'item_stack_count', 'damage', 'dist_on_freefall', 'playing_type_3', 'rank'], inplace=True)\n",
    "index_train, index_test = train_test_split(range(df_pysurvival_aft.shape[0]), test_size = 0.2, random_state=20)\n",
    "data_train = df_pysurvival_aft.loc[index_train].reset_index(drop=True)\n",
    "data_test  = df_pysurvival_aft.loc[index_test].reset_index(drop=True)\n",
    "X_train, X_test = data_train.drop(columns=['death_time', 'event']), data_test.drop(columns=['death_time', 'event'])\n",
    "T_train, T_test = data_train['death_time'].values, data_test['death_time'].values\n",
    "E_train, E_test = data_train['event'].values, data_test['event'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ll_model = LogLogisticModel()\n",
    "#ln_model.fit(X_train, T_train, E_train, init_method='zeros', lr=3.62e-4, num_epochs=2000, optimizer='adam')\n",
    "ll_model.fit(X_train, T_train, E_train, init_method='glorot_uniform', lr=3.6e-4, num_epochs=2000, optimizer='adam')\n",
    "#ln_model.fit(X_train, T_train, E_train, init_method='glorot_normal', lr=3.42e-4, num_epochs=2000, optimizer='adam')\n",
    "display_loss_values(ll_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 5 - Cross Validation / Model Performances / C-INDEX\n",
    "c_index = concordance_index(ll_model, X_test, T_test, E_test)\n",
    "print('C-index: {:.2f}'.format(c_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = ln_model.predict_risk(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sksurv IPCRidge AFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import IPCRidge\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_aft_sksurv = model_data()\n",
    "df_aft_sksurv = pd.concat([df_aft_sksurv, pd.get_dummies(df_aft_sksurv['playing_type'], prefix='playing_type')], axis=1)\n",
    "df_aft_sksurv.rename(columns={\"playing_type_1\":\"solo\", \"playing_type_2\":\"duo\", \"playing_type_3\":\"squad\"}, inplace=True)\n",
    "#del multikolinearumo pasalinam duo playing_type_2 atributa\n",
    "df_aft_sksurv.drop(columns=['duo'], inplace=True)\n",
    "#df_aft_sksurv.loc[(df_aft_sksurv['solo'] == 0) & (df_aft_sksurv['squad'] == 0), 'squad'] = 1\n",
    "\n",
    "df_aft_sksurv.drop(columns=['distance_sum', 'index', 'playing_type', 'assist', 'item_stack_count', 'damage', 'dist_on_freefall', 'rank'], inplace=True)\n",
    "#df_aft_sksurv['death_time'] = df_aft_sksurv['death_time'].div(60).round(3)\n",
    "Xt = df_aft_sksurv.drop(columns=['death_time', 'event'])\n",
    "y = df_aft_sksurv[['event', 'death_time']]\n",
    "y['event'] = y['event'].astype('bool')\n",
    "s = y.dtypes\n",
    "yt = np.array([tuple(x) for x in y.values], dtype=list(zip(s.index, s)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xt, yt, test_size=0.3, random_state=20)\n",
    "\n",
    "aft_sksurv = IPCRidge(alpha=0.1)\n",
    "aft_sksurv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_score_features(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    scores = np.empty(n_features)\n",
    "    m = IPCRidge(alpha=0.1)\n",
    "    for j in range(n_features):\n",
    "        Xj = X[:, j:j+1]\n",
    "        m.fit(Xj, y)\n",
    "        scores[j] = m.score(-Xj, y)\n",
    "    return scores\n",
    "\n",
    "scores = fit_and_score_features(X_train.values, y_train)\n",
    "pd.Series(scores, index=X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min, train_max = y_train['death_time'].min(), y_train['death_time'].max()\n",
    "test_min, test_max = y_test['death_time'].min(), y_test[\"death_time\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import (concordance_index_censored,concordance_index_ipcw,cumulative_dynamic_auc)\n",
    "pred_aft = aft_sksurv.predict(X_test)\n",
    "res_c = concordance_index_censored(y_test['event'], y_test['death_time'], -np.log(pred_aft))\n",
    "res_ipcw = concordance_index_ipcw(y_train, y_test, -np.log(pred_aft), tau=times[-1])\n",
    "res_c[0]\n",
    "res_ipcw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(1.5, 31, 1)\n",
    "va_auc, va_mean_auc = cumulative_dynamic_auc(y_train, y_test, -np.log(pred_aft), times)\n",
    "plt.plot(times, va_auc, marker=\"o\")\n",
    "plt.xlabel(\"Playing time (min)\")\n",
    "plt.axhline(va_mean_auc, linestyle=\"--\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.grid(True)\n",
    "va_mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from pysurvival import utils\n",
    "from pysurvival.models.non_parametric import KaplanMeierModel\n",
    "from pysurvival import utils\n",
    "from pysurvival.utils import metrics\n",
    "\n",
    "def act_to_est(model, X, T, E, figure_size, times = None,  metrics = ['rmse', 'mean', 'median']):\n",
    "    kmf = KaplanMeierModel()\n",
    "    kmf.fit(T, E)\n",
    "    N = T.shape[0]\n",
    "    if times is None:\n",
    "        times = kmf.times\n",
    "    actual = []\n",
    "    predicted = []\n",
    "\n",
    "    model_pred =  np.sum(model.predict_density(X), 0)\n",
    "    for t in times:\n",
    "        min_index = [abs(aj1-t) for (aj1, aj) in model.time_buckets]\n",
    "        index = np.argmin(min_index)\n",
    "        actual.append(N*kmf.predict_density(X,t))\n",
    "        predicted.append(model_pred[index])\n",
    "\n",
    "    results = None\n",
    "    title = 'Realus ir prognozuojamas ivykių skaičius'\n",
    "    if metrics is not None:\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "        med_ae = median_absolute_error(actual, predicted)\n",
    "        mae = mean_absolute_error(actual, predicted)\n",
    "\n",
    "        #jei ivertinimo reikia tik vieno\n",
    "        if isinstance(metrics, str) :\n",
    "            if 'rmse' in metrics.lower() or 'root' in metrics.lower():\n",
    "                results = rmse\n",
    "                title += \"\\n Šaknis iš vidutinės kvadratinės paklaidos = {:.3f}\".format(rmse)\n",
    "            elif 'median' in metrics.lower() :\n",
    "                results = med_ae\n",
    "                title += \"\\n Absoliutinės paklaidos mediana = {:.3f}\".format(med_ae)\n",
    "            elif 'mean' in metrics.lower() :\n",
    "                results = mae\n",
    "                title += \"\\n Vidutinė absoliutinė paklaida = {:.3f}\".format(mae)\n",
    "            else:\n",
    "                raise NotImplementedError('{} nėra tokio įvertinimo'.format(metrics))\n",
    "\n",
    "        #jei reikalingu ivertinimu reikia saraso\n",
    "        elif isinstance(metrics, list):\n",
    "            results = {}\n",
    "            is_rmse = False\n",
    "            if any( [ ('rmse' in m.lower() or 'root' in m.lower()) \\\n",
    "                for m in metrics ]):\n",
    "                is_rmse = True\n",
    "                results['rmse'] = rmse\n",
    "                title += \"\\n Šaknis iš vidutinės kvadratinės paklaidos = {:.3f}\".format(rmse)\n",
    "            is_med_ae = False\n",
    "            if any( ['median' in m.lower() for m in metrics ]):\n",
    "                is_med_ae = True\n",
    "                results['median'] = med_ae\n",
    "                title += \"\\n Absoliutinių paklaidų mediana = {:.3f}\".format(med_ae)\n",
    "            is_mae = False\n",
    "            if any( ['mean' in m.lower() for m in metrics ]):\n",
    "                is_mae = True\n",
    "                results['mean'] = mae\n",
    "                title += \"\\n Vidutinė absoliutinė paklaida = {:.3f}\".format(mae)\n",
    "            if all([not is_mae, not is_rmse, not is_med_ae]):\n",
    "                error = 'Nurodyti vertinimai nerasti'\n",
    "                raise NotImplementedError(error)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    ax.plot(times, actual, color='red', label='Realus', alpha=0.8, lw = 3)\n",
    "    ax.plot(times, predicted, color='blue', label='Prognozuojamas', alpha=0.8, lw = 3)\n",
    "    plt.xlim(0, max(T))\n",
    "    ax.set_ylim(0)\n",
    "    plt.xlabel('Laikas (min)', fontsize=13)\n",
    "    plt.ylabel('Įvykių skaičius', fontsize=13)\n",
    "    plt.title(title, fontsize = 15)\n",
    "    plt.legend(fontsize = 15)\n",
    "    plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_end = act_to_est(ll_model, X_test, T_test, E_test, figure_size=(15, 6), metrics=['rmse', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysurvival.utils.metrics import brier_score\n",
    "def brier_score_plot(model, X, T, E, figure_size):\n",
    "    \n",
    "    times, brier_scores = brier_score(model, X, T, E)\n",
    "    times.insert(0, 0)\n",
    "    brier_scores.insert(0, 0)\n",
    "    ibs_value = np.trapz(brier_scores, times)/max(T)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figure_size)\n",
    "    title = 'Brier įvertinimų vidurkis = {:.2f}'\n",
    "    title = title.format(ibs_value)\n",
    "    ax.axhline(y=0.25, ls = 'dotted', color = 'red')\n",
    "    ax.plot(times, brier_scores, color = 'blue', lw = 2)\n",
    "    ax.set_xlim(0, max(T))\n",
    "    ax.set_ylim(0)\n",
    "    plt.xlabel('Laikas (min)', fontsize=13)\n",
    "    plt.ylabel('Brier įvertinimas BS(t)', fontsize=13)\n",
    "    ax.axhline(y=0.25, ls = 'dotted', color = 'red')\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.show()\n",
    "    return ibs_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibs = brier_score_plot(ll_model, X_test, T_test, E_test, figure_size=(15, 6))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit9232193387bb45be8261a6a16a0ff108",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}